{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10cccd0d-b9fe-42af-b560-619185994cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "demo=open('Downloads/demotext.txt','r')\n",
    "text=demo.read()\n",
    "text\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274b19f-f4bf-4330-882b-31297994a71e",
   "metadata": {},
   "source": [
    "# Tokenization of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f670322-6e2f-465f-8840-95fdf001c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96e3971f-1f93-4054-8282-78ea1b211b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\mutyalasravanthi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c886aef-0a89-40c5-bc59-a414bcf64a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is Lorem Ipsum?',\n",
       " 'Lorem Ipsum is simply dummy text of the printing and \\ntypesetting industry.',\n",
       " \"Lorem Ipsum has been the industry's \\nstandard dummy text ever since the 1500s, when an unknown \\nprinter took a galley of type and scrambled it to make a \\ntype specimen book.\",\n",
       " 'It has survived not only five centuries, \\nbut also the leap into electronic typesetting, \\nremaining essentially unchanged.',\n",
       " 'It was popularised in the 1960s with the release of Letraset \\nsheets containing Lorem Ipsum passages, and more recently \\nwith desktop publishing software like Aldus PageMaker \\nincluding versions of Lorem Ipsum.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Tokenization\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49e46e15-fbd2-40c7-9071-36271e37b845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'is',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " '?',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " 'is',\n",
       " 'simply',\n",
       " 'dummy',\n",
       " 'text',\n",
       " 'of',\n",
       " 'the',\n",
       " 'printing',\n",
       " 'and',\n",
       " 'typesetting',\n",
       " 'industry',\n",
       " '.',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " 'has',\n",
       " 'been',\n",
       " 'the',\n",
       " 'industry',\n",
       " \"'s\",\n",
       " 'standard',\n",
       " 'dummy',\n",
       " 'text',\n",
       " 'ever',\n",
       " 'since',\n",
       " 'the',\n",
       " '1500s',\n",
       " ',',\n",
       " 'when',\n",
       " 'an',\n",
       " 'unknown',\n",
       " 'printer',\n",
       " 'took',\n",
       " 'a',\n",
       " 'galley',\n",
       " 'of',\n",
       " 'type',\n",
       " 'and',\n",
       " 'scrambled',\n",
       " 'it',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'type',\n",
       " 'specimen',\n",
       " 'book',\n",
       " '.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'survived',\n",
       " 'not',\n",
       " 'only',\n",
       " 'five',\n",
       " 'centuries',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'the',\n",
       " 'leap',\n",
       " 'into',\n",
       " 'electronic',\n",
       " 'typesetting',\n",
       " ',',\n",
       " 'remaining',\n",
       " 'essentially',\n",
       " 'unchanged',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'popularised',\n",
       " 'in',\n",
       " 'the',\n",
       " '1960s',\n",
       " 'with',\n",
       " 'the',\n",
       " 'release',\n",
       " 'of',\n",
       " 'Letraset',\n",
       " 'sheets',\n",
       " 'containing',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " 'passages',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " 'recently',\n",
       " 'with',\n",
       " 'desktop',\n",
       " 'publishing',\n",
       " 'software',\n",
       " 'like',\n",
       " 'Aldus',\n",
       " 'PageMaker',\n",
       " 'including',\n",
       " 'versions',\n",
       " 'of',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " '.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Tokenization\n",
    "tokens=word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69c0ee-068f-4f0c-9ebd-a06a15f75aba",
   "metadata": {},
   "source": [
    "# Lemmatization : Root word of the given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0033474-ae94-40cd-ac51-ad6aaa8e0765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mutyalasravanthi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Root word of the given word.\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38559539-17de-44c9-8b76-c70dff0cfdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book\n",
      "version\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "print(lem.lemmatize(\"books\")) #words choosen from the text. \n",
    "print(lem.lemmatize(\"versions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fde779-def9-4c3c-89d8-2d15a5caeff5",
   "metadata": {},
   "source": [
    "# Stop Words : The words connecting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b9368c4-08f3-40ad-8c6a-30df8453f00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mutyalasravanthi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc47045-dd9f-4d84-8f02-d3a9c5372170",
   "metadata": {},
   "source": [
    "# Bigrams, trigrams and ngrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a03e96cb-5859-4972-8f14-3695ba2b6922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'is',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " '?',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " 'is',\n",
       " 'simply',\n",
       " 'dummy',\n",
       " 'text',\n",
       " 'of',\n",
       " 'the',\n",
       " 'printing',\n",
       " 'and',\n",
       " 'typesetting',\n",
       " 'industry',\n",
       " '.',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " 'has',\n",
       " 'been',\n",
       " 'the',\n",
       " 'industry',\n",
       " \"'s\",\n",
       " 'standard',\n",
       " 'dummy',\n",
       " 'text',\n",
       " 'ever',\n",
       " 'since',\n",
       " 'the',\n",
       " '1500s',\n",
       " ',',\n",
       " 'when',\n",
       " 'an',\n",
       " 'unknown',\n",
       " 'printer',\n",
       " 'took',\n",
       " 'a',\n",
       " 'galley',\n",
       " 'of',\n",
       " 'type',\n",
       " 'and',\n",
       " 'scrambled',\n",
       " 'it',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'type',\n",
       " 'specimen',\n",
       " 'book',\n",
       " '.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'survived',\n",
       " 'not',\n",
       " 'only',\n",
       " 'five',\n",
       " 'centuries',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'the',\n",
       " 'leap',\n",
       " 'into',\n",
       " 'electronic',\n",
       " 'typesetting',\n",
       " ',',\n",
       " 'remaining',\n",
       " 'essentially',\n",
       " 'unchanged',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'popularised',\n",
       " 'in',\n",
       " 'the',\n",
       " '1960s',\n",
       " 'with',\n",
       " 'the',\n",
       " 'release',\n",
       " 'of',\n",
       " 'Letraset',\n",
       " 'sheets',\n",
       " 'containing',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " 'passages',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " 'recently',\n",
       " 'with',\n",
       " 'desktop',\n",
       " 'publishing',\n",
       " 'software',\n",
       " 'like',\n",
       " 'Aldus',\n",
       " 'PageMaker',\n",
       " 'including',\n",
       " 'versions',\n",
       " 'of',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " '.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "token_1 = nltk.word_tokenize(text)\n",
    "token_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8e5f2bd-efac-48cf-9a97-f5f0111c9829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams..\n",
      "\n",
      "[('What', 'is'), ('is', 'Lorem'), ('Lorem', 'Ipsum'), ('Ipsum', '?'), ('?', 'Lorem'), ('Lorem', 'Ipsum'), ('Ipsum', 'is'), ('is', 'simply'), ('simply', 'dummy'), ('dummy', 'text'), ('text', 'of'), ('of', 'the'), ('the', 'printing'), ('printing', 'and'), ('and', 'typesetting'), ('typesetting', 'industry'), ('industry', '.'), ('.', 'Lorem'), ('Lorem', 'Ipsum'), ('Ipsum', 'has'), ('has', 'been'), ('been', 'the'), ('the', 'industry'), ('industry', \"'s\"), (\"'s\", 'standard'), ('standard', 'dummy'), ('dummy', 'text'), ('text', 'ever'), ('ever', 'since'), ('since', 'the'), ('the', '1500s'), ('1500s', ','), (',', 'when'), ('when', 'an'), ('an', 'unknown'), ('unknown', 'printer'), ('printer', 'took'), ('took', 'a'), ('a', 'galley'), ('galley', 'of'), ('of', 'type'), ('type', 'and'), ('and', 'scrambled'), ('scrambled', 'it'), ('it', 'to'), ('to', 'make'), ('make', 'a'), ('a', 'type'), ('type', 'specimen'), ('specimen', 'book'), ('book', '.'), ('.', 'It'), ('It', 'has'), ('has', 'survived'), ('survived', 'not'), ('not', 'only'), ('only', 'five'), ('five', 'centuries'), ('centuries', ','), (',', 'but'), ('but', 'also'), ('also', 'the'), ('the', 'leap'), ('leap', 'into'), ('into', 'electronic'), ('electronic', 'typesetting'), ('typesetting', ','), (',', 'remaining'), ('remaining', 'essentially'), ('essentially', 'unchanged'), ('unchanged', '.'), ('.', 'It'), ('It', 'was'), ('was', 'popularised'), ('popularised', 'in'), ('in', 'the'), ('the', '1960s'), ('1960s', 'with'), ('with', 'the'), ('the', 'release'), ('release', 'of'), ('of', 'Letraset'), ('Letraset', 'sheets'), ('sheets', 'containing'), ('containing', 'Lorem'), ('Lorem', 'Ipsum'), ('Ipsum', 'passages'), ('passages', ','), (',', 'and'), ('and', 'more'), ('more', 'recently'), ('recently', 'with'), ('with', 'desktop'), ('desktop', 'publishing'), ('publishing', 'software'), ('software', 'like'), ('like', 'Aldus'), ('Aldus', 'PageMaker'), ('PageMaker', 'including'), ('including', 'versions'), ('versions', 'of'), ('of', 'Lorem'), ('Lorem', 'Ipsum'), ('Ipsum', '.')] \n",
      "\n",
      "Trigrams...\n",
      "\n",
      "[('What', 'is', 'Lorem'), ('is', 'Lorem', 'Ipsum'), ('Lorem', 'Ipsum', '?'), ('Ipsum', '?', 'Lorem'), ('?', 'Lorem', 'Ipsum'), ('Lorem', 'Ipsum', 'is'), ('Ipsum', 'is', 'simply'), ('is', 'simply', 'dummy'), ('simply', 'dummy', 'text'), ('dummy', 'text', 'of'), ('text', 'of', 'the'), ('of', 'the', 'printing'), ('the', 'printing', 'and'), ('printing', 'and', 'typesetting'), ('and', 'typesetting', 'industry'), ('typesetting', 'industry', '.'), ('industry', '.', 'Lorem'), ('.', 'Lorem', 'Ipsum'), ('Lorem', 'Ipsum', 'has'), ('Ipsum', 'has', 'been'), ('has', 'been', 'the'), ('been', 'the', 'industry'), ('the', 'industry', \"'s\"), ('industry', \"'s\", 'standard'), (\"'s\", 'standard', 'dummy'), ('standard', 'dummy', 'text'), ('dummy', 'text', 'ever'), ('text', 'ever', 'since'), ('ever', 'since', 'the'), ('since', 'the', '1500s'), ('the', '1500s', ','), ('1500s', ',', 'when'), (',', 'when', 'an'), ('when', 'an', 'unknown'), ('an', 'unknown', 'printer'), ('unknown', 'printer', 'took'), ('printer', 'took', 'a'), ('took', 'a', 'galley'), ('a', 'galley', 'of'), ('galley', 'of', 'type'), ('of', 'type', 'and'), ('type', 'and', 'scrambled'), ('and', 'scrambled', 'it'), ('scrambled', 'it', 'to'), ('it', 'to', 'make'), ('to', 'make', 'a'), ('make', 'a', 'type'), ('a', 'type', 'specimen'), ('type', 'specimen', 'book'), ('specimen', 'book', '.'), ('book', '.', 'It'), ('.', 'It', 'has'), ('It', 'has', 'survived'), ('has', 'survived', 'not'), ('survived', 'not', 'only'), ('not', 'only', 'five'), ('only', 'five', 'centuries'), ('five', 'centuries', ','), ('centuries', ',', 'but'), (',', 'but', 'also'), ('but', 'also', 'the'), ('also', 'the', 'leap'), ('the', 'leap', 'into'), ('leap', 'into', 'electronic'), ('into', 'electronic', 'typesetting'), ('electronic', 'typesetting', ','), ('typesetting', ',', 'remaining'), (',', 'remaining', 'essentially'), ('remaining', 'essentially', 'unchanged'), ('essentially', 'unchanged', '.'), ('unchanged', '.', 'It'), ('.', 'It', 'was'), ('It', 'was', 'popularised'), ('was', 'popularised', 'in'), ('popularised', 'in', 'the'), ('in', 'the', '1960s'), ('the', '1960s', 'with'), ('1960s', 'with', 'the'), ('with', 'the', 'release'), ('the', 'release', 'of'), ('release', 'of', 'Letraset'), ('of', 'Letraset', 'sheets'), ('Letraset', 'sheets', 'containing'), ('sheets', 'containing', 'Lorem'), ('containing', 'Lorem', 'Ipsum'), ('Lorem', 'Ipsum', 'passages'), ('Ipsum', 'passages', ','), ('passages', ',', 'and'), (',', 'and', 'more'), ('and', 'more', 'recently'), ('more', 'recently', 'with'), ('recently', 'with', 'desktop'), ('with', 'desktop', 'publishing'), ('desktop', 'publishing', 'software'), ('publishing', 'software', 'like'), ('software', 'like', 'Aldus'), ('like', 'Aldus', 'PageMaker'), ('Aldus', 'PageMaker', 'including'), ('PageMaker', 'including', 'versions'), ('including', 'versions', 'of'), ('versions', 'of', 'Lorem'), ('of', 'Lorem', 'Ipsum'), ('Lorem', 'Ipsum', '.')] \n",
      "\n",
      "Ngrams..\n",
      "\n",
      "[('What',), ('is',), ('Lorem',), ('Ipsum?',), ('Lorem',), ('Ipsum',), ('is',), ('simply',), ('dummy',), ('text',), ('of',), ('the',), ('printing',), ('and',), ('typesetting',), ('industry.',), ('Lorem',), ('Ipsum',), ('has',), ('been',), ('the',), (\"industry's\",), ('standard',), ('dummy',), ('text',), ('ever',), ('since',), ('the',), ('1500s,',), ('when',), ('an',), ('unknown',), ('printer',), ('took',), ('a',), ('galley',), ('of',), ('type',), ('and',), ('scrambled',), ('it',), ('to',), ('make',), ('a',), ('type',), ('specimen',), ('book.',), ('It',), ('has',), ('survived',), ('not',), ('only',), ('five',), ('centuries,',), ('but',), ('also',), ('the',), ('leap',), ('into',), ('electronic',), ('typesetting,',), ('remaining',), ('essentially',), ('unchanged.',), ('It',), ('was',), ('popularised',), ('in',), ('the',), ('1960s',), ('with',), ('the',), ('release',), ('of',), ('Letraset',), ('sheets',), ('containing',), ('Lorem',), ('Ipsum',), ('passages,',), ('and',), ('more',), ('recently',), ('with',), ('desktop',), ('publishing',), ('software',), ('like',), ('Aldus',), ('PageMaker',), ('including',), ('versions',), ('of',), ('Lorem',), ('Ipsum.',)]\n"
     ]
    }
   ],
   "source": [
    "# bigrams\n",
    "bg=list(nltk.bigrams(token_1))\n",
    "print(\"Bigrams..\\n\")\n",
    "print(bg,\"\\n\")\n",
    "\n",
    "# trigrams\n",
    "tg=list(nltk.trigrams(token_1))\n",
    "print(\"Trigrams...\\n\")\n",
    "print(tg,\"\\n\")\n",
    "\n",
    "# Ngrams\n",
    "ng = list(ngrams(text.split(),1))\n",
    "print(\"Ngrams..\\n\")\n",
    "print(ng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64385f67-da40-46da-828c-1da67d2053fe",
   "metadata": {},
   "source": [
    "# POS Tagging :process of labeling tokens with their respective parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4a1bbf5-6e59-4067-acfb-881b310f7a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mutyalasravanthi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS Tagging\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf7bb19e-ee1c-46d6-ba41-96109e0922d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\mutyalasravanthi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger_eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dac4e64c-9ada-411f-b66a-c465cf57f1ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 'WP')]\n",
      "[('is', 'VBZ')]\n",
      "[('Lorem', 'NN')]\n",
      "[('Ipsum', 'NN')]\n",
      "[('?', '.')]\n",
      "[('Lorem', 'NN')]\n",
      "[('Ipsum', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('simply', 'RB')]\n",
      "[('dummy', 'NN')]\n",
      "[('text', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('printing', 'NN')]\n",
      "[('and', 'CC')]\n",
      "[('typesetting', 'VBG')]\n",
      "[('industry', 'NN')]\n",
      "[('.', '.')]\n",
      "[('Lorem', 'NN')]\n",
      "[('Ipsum', 'NN')]\n",
      "[('has', 'VBZ')]\n",
      "[('been', 'VBN')]\n",
      "[('the', 'DT')]\n",
      "[('industry', 'NN')]\n",
      "[(\"'s\", 'POS')]\n",
      "[('standard', 'NN')]\n",
      "[('dummy', 'NN')]\n",
      "[('text', 'NN')]\n",
      "[('ever', 'RB')]\n",
      "[('since', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('1500s', 'CD')]\n",
      "[(',', ',')]\n",
      "[('when', 'WRB')]\n",
      "[('an', 'DT')]\n",
      "[('unknown', 'JJ')]\n",
      "[('printer', 'NN')]\n",
      "[('took', 'VBD')]\n",
      "[('a', 'DT')]\n",
      "[('galley', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('type', 'NN')]\n",
      "[('and', 'CC')]\n",
      "[('scrambled', 'VBN')]\n",
      "[('it', 'PRP')]\n",
      "[('to', 'TO')]\n",
      "[('make', 'VB')]\n",
      "[('a', 'DT')]\n",
      "[('type', 'NN')]\n",
      "[('specimen', 'NNS')]\n",
      "[('book', 'NN')]\n",
      "[('.', '.')]\n",
      "[('It', 'PRP')]\n",
      "[('has', 'VBZ')]\n",
      "[('survived', 'VBN')]\n",
      "[('not', 'RB')]\n",
      "[('only', 'RB')]\n",
      "[('five', 'CD')]\n",
      "[('centuries', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('but', 'CC')]\n",
      "[('also', 'RB')]\n",
      "[('the', 'DT')]\n",
      "[('leap', 'NN')]\n",
      "[('into', 'IN')]\n",
      "[('electronic', 'JJ')]\n",
      "[('typesetting', 'VBG')]\n",
      "[(',', ',')]\n",
      "[('remaining', 'VBG')]\n",
      "[('essentially', 'RB')]\n",
      "[('unchanged', 'JJ')]\n",
      "[('.', '.')]\n",
      "[('It', 'PRP')]\n",
      "[('was', 'VBD')]\n",
      "[('popularised', 'VBN')]\n",
      "[('in', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('1960s', 'NNS')]\n",
      "[('with', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('release', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('Letraset', 'VB')]\n",
      "[('sheets', 'NNS')]\n",
      "[('containing', 'VBG')]\n",
      "[('Lorem', 'NN')]\n",
      "[('Ipsum', 'NN')]\n",
      "[('passages', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('more', 'RBR')]\n",
      "[('recently', 'RB')]\n",
      "[('with', 'IN')]\n",
      "[('desktop', 'NN')]\n",
      "[('publishing', 'NN')]\n",
      "[('software', 'NN')]\n",
      "[('like', 'IN')]\n",
      "[('Aldus', 'NN')]\n",
      "[('PageMaker', 'NN')]\n",
      "[('including', 'VBG')]\n",
      "[('versions', 'NNS')]\n",
      "[('of', 'IN')]\n",
      "[('Lorem', 'NN')]\n",
      "[('Ipsum', 'NN')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe92e4-b0b3-4de5-b9a7-6f92274fa29e",
   "metadata": {},
   "source": [
    "# Stop words: Common words which are ignored by most engines because their inclusion increase the size of the index without improving precision or recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5bfe87c-40ab-44d5-b36f-9790b9419ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mutyalasravanthi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop Words\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fe44c7d-f286-4fb9-919b-eb7ab57b6b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'is',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " '?',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " 'is',\n",
       " 'simply',\n",
       " 'dummy',\n",
       " 'text',\n",
       " 'of',\n",
       " 'the',\n",
       " 'printing',\n",
       " 'and',\n",
       " 'typesetting',\n",
       " 'industry',\n",
       " '.',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " 'has',\n",
       " 'been',\n",
       " 'the',\n",
       " 'industry',\n",
       " \"'s\",\n",
       " 'standard',\n",
       " 'dummy',\n",
       " 'text',\n",
       " 'ever',\n",
       " 'since',\n",
       " 'the',\n",
       " '1500s',\n",
       " ',',\n",
       " 'when',\n",
       " 'an',\n",
       " 'unknown',\n",
       " 'printer',\n",
       " 'took',\n",
       " 'a',\n",
       " 'galley',\n",
       " 'of',\n",
       " 'type',\n",
       " 'and',\n",
       " 'scrambled',\n",
       " 'it',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'type',\n",
       " 'specimen',\n",
       " 'book',\n",
       " '.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'survived',\n",
       " 'not',\n",
       " 'only',\n",
       " 'five',\n",
       " 'centuries',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'the',\n",
       " 'leap',\n",
       " 'into',\n",
       " 'electronic',\n",
       " 'typesetting',\n",
       " ',',\n",
       " 'remaining',\n",
       " 'essentially',\n",
       " 'unchanged',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'popularised',\n",
       " 'in',\n",
       " 'the',\n",
       " '1960s',\n",
       " 'with',\n",
       " 'the',\n",
       " 'release',\n",
       " 'of',\n",
       " 'Letraset',\n",
       " 'sheets',\n",
       " 'containing',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " 'passages',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " 'recently',\n",
       " 'with',\n",
       " 'desktop',\n",
       " 'publishing',\n",
       " 'software',\n",
       " 'like',\n",
       " 'Aldus',\n",
       " 'PageMaker',\n",
       " 'including',\n",
       " 'versions',\n",
       " 'of',\n",
       " 'Lorem',\n",
       " 'Ipsum',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens #word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4777916-064f-435d-9d8f-77e4b64313cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_word = stopwords.words('english')\n",
    "print(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8663c17a-1ace-4bee-85bc-c7522df89910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered_words (without Stopwords)\n",
      " ['What', 'Lorem', 'Ipsum', '?', 'Lorem', 'Ipsum', 'simply', 'dummy', 'text', 'printing', 'typesetting', 'industry', '.', 'Lorem', 'Ipsum', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', '1500s', ',', 'unknown', 'printer', 'took', 'galley', 'type', 'scrambled', 'make', 'type', 'specimen', 'book', '.', 'It', 'survived', 'five', 'centuries', ',', 'also', 'leap', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.', 'It', 'popularised', '1960s', 'release', 'Letraset', 'sheets', 'containing', 'Lorem', 'Ipsum', 'passages', ',', 'recently', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'Lorem', 'Ipsum', '.']\n"
     ]
    }
   ],
   "source": [
    "# removing stop words\n",
    "filter = [w for w in tokens if not w in stop_word]\n",
    "print('Filtered_words (without Stopwords)\\n',filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd268d7-4120-4216-93a8-5ee7d82991fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
